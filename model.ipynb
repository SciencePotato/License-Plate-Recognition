{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        if root.find('object'):\n",
    "            for member in root.findall('object'):\n",
    "                bbx = member.find('bndbox')                \n",
    "                xmin = round(float(bbx.find('xmin').text))\n",
    "                ymin = round(float(bbx.find('ymin').text))\n",
    "                xmax = round(float(bbx.find('xmax').text))\n",
    "                ymax = round(float(bbx.find('ymax').text))\n",
    "                label = member.find('name').text\n",
    "                value = (root.find('filename').text,\n",
    "                        int(root.find('size')[0].text),\n",
    "                        int(root.find('size')[1].text),\n",
    "                        label,\n",
    "                        xmin,\n",
    "                        ymin,\n",
    "                        xmax,\n",
    "                        ymax\n",
    "                        )\n",
    "                xml_list.append(value)\n",
    "\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xmlDf = pd.DataFrame(xml_list, columns=column_name, index=None)\n",
    "    return xmlDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xml_to_csv(\"data/annotations/\")\n",
    "\n",
    "height = 256\n",
    "width = 256\n",
    "train = df.iloc[:(int)(len(df) * 0.7), :]\n",
    "train.to_csv(\"data/train_data.csv\", index=None)\n",
    "test = df.iloc[(int)(len(df) * 0.3):, :]\n",
    "test.to_csv(\"data/test_data.csv\", index=None)\n",
    "\n",
    "training_image_label = pd.read_csv(\"data/train_data.csv\")\n",
    "train_images = []\n",
    "train_targets = []\n",
    "train_labels = []\n",
    "\n",
    "testing_image_label = pd.read_csv(\"data/train_data.csv\")\n",
    "test_images = []\n",
    "test_targets = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in training_image_label.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    train_image_fullpath = os.path.join(\"data/images/\", filename)\n",
    "    train_img = keras.preprocessing.image.load_img(train_image_fullpath, target_size=(height, width))\n",
    "    train_img_arr = keras.preprocessing.image.img_to_array(train_img)\n",
    "\n",
    "\n",
    "    # Bounding Box Coordinate\n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    train_images.append(train_img_arr)\n",
    "    train_targets.append((xmin, ymin, xmax, ymax))\n",
    "    train_labels.append(class_name)\n",
    "    \n",
    "for index, row in testing_image_label.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    test_image_fullpath = os.path.join(\"data/images/\", filename)\n",
    "    test_img = keras.preprocessing.image.load_img(test_image_fullpath, target_size=(height, width))\n",
    "    test_img_arr = keras.preprocessing.image.img_to_array(test_img)\n",
    "    \n",
    "    # Bounding Box Coordinate\n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    test_images.append(test_img_arr)\n",
    "    test_targets.append((xmin, ymin, xmax, ymax))\n",
    "    test_labels.append(class_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.asarray(train_images, dtype=\"object\")\n",
    "train_targets = np.array(train_targets)\n",
    "train_labels = np.array(train_labels)\n",
    "validation_images = np.asarray(test_images, dtype=\"object\")\n",
    "validation_targets = np.array(test_targets)\n",
    "validation_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "#create the common input layer\n",
    "input_shape = (256, 256, 3)\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "num_classes = 2\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str224",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m trainTargets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_labels,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_targets\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m validationTargets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcl_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_labels,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbb_head\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_targets\n\u001b[1;32m     12\u001b[0m }\n\u001b[0;32m---> 14\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainTargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/optree/ops.py:521\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    519\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m    520\u001b[0m flat_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(func, \u001b[38;5;241m*\u001b[39mflat_args)\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_results\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: str224"
     ]
    }
   ],
   "source": [
    "losses = {\"cl_head\":tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "   \"bb_head\":tf.keras.losses.MSE}\n",
    "model.compile(loss=losses, optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "trainTargets = {\n",
    "    \"cl_head\": train_labels,\n",
    "    \"bb_head\": train_targets\n",
    "}\n",
    "validationTargets = {\n",
    "    \"cl_head\": test_labels,\n",
    "    \"bb_head\": test_targets\n",
    "}\n",
    "\n",
    "history = model.fit(train_images, trainTargets, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
