{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras import models\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        if root.find('object'):\n",
    "            for member in root.findall('object'):\n",
    "                bbx = member.find('bndbox')                \n",
    "                xmin = round(float(bbx.find('xmin').text))\n",
    "                ymin = round(float(bbx.find('ymin').text))\n",
    "                xmax = round(float(bbx.find('xmax').text))\n",
    "                ymax = round(float(bbx.find('ymax').text))\n",
    "                label = member.find('name').text\n",
    "                value = (root.find('filename').text,\n",
    "                        int(root.find('size')[0].text),\n",
    "                        int(root.find('size')[1].text),\n",
    "                        label,\n",
    "                        xmin,\n",
    "                        ymin,\n",
    "                        xmax,\n",
    "                        ymax\n",
    "                        )\n",
    "                xml_list.append(value)\n",
    "\n",
    "    column_name = ['filename', 'width', 'height',\n",
    "                   'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xmlDf = pd.DataFrame(xml_list, columns=column_name, index=None)\n",
    "    return xmlDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = xml_to_csv(\"data/annotations/\")\n",
    "\n",
    "train = df.iloc[:(int)(len(df) * 0.7), :]\n",
    "train.to_csv(\"data/train_data.csv\", index=None)\n",
    "test = df.iloc[(int)(len(df) * 0.3):, :]\n",
    "test.to_csv(\"data/test_data.csv\", index=None)\n",
    "\n",
    "training_image_label = pd.read_csv(\"data/train_data.csv\")\n",
    "train_images = []\n",
    "train_targets = []\n",
    "train_labels = []\n",
    "\n",
    "testing_image_label = pd.read_csv(\"data/train_data.csv\")\n",
    "test_images = []\n",
    "test_targets = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in training_image_label.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    train_image_fullpath = os.path.join(\"data/images/\", filename)\n",
    "    train_img = keras.preprocessing.image.load_img(train_image_fullpath, target_size=(height, width))\n",
    "    train_img_arr = keras.preprocessing.image.img_to_array(train_img)\n",
    "    \n",
    "    # Bounding Box Coordinate\n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    train_images.append(train_img_arr)\n",
    "    train_targets.append((xmin, ymin, xmax, ymax))\n",
    "    train_labels.append(class_name)\n",
    "    \n",
    "for index, row in testing_image_label.iterrows():\n",
    "    (filename, width, height, class_name, xmin, ymin, xmax, ymax) = row\n",
    "    \n",
    "    test_image_fullpath = os.path.join(\"data/images/\", filename)\n",
    "    test_img = keras.preprocessing.image.load_img(test_image_fullpath, target_size=(height, width))\n",
    "    test_img_arr = keras.preprocessing.image.img_to_array(test_img)\n",
    "    \n",
    "    # Bounding Box Coordinate\n",
    "    xmin = round(xmin/ width, 2)\n",
    "    ymin = round(ymin/ height, 2)\n",
    "    xmax = round(xmax/ width, 2)\n",
    "    ymax = round(ymax/ height, 2)\n",
    "    \n",
    "    test_images.append(train_img_arr)\n",
    "    test_targets.append((xmin, ymin, xmax, ymax))\n",
    "    test_labels.append(class_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     19\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_images\u001b[49m, train_labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(test_images, test_labels))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     25\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "#create the common input layer\n",
    "input_shape = (400, 400, 3)\n",
    "input_layer = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)  # Output layer with 10 units (number of classes)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
